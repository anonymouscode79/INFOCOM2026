{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from itertools import combinations\n",
    "from torch.utils.data import TensorDataset,DataLoader\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_binary_classification(X:np.ndarray,y:np.ndarray):\n",
    "    return X,(y!=0).astype(int)\n",
    "def sepearte_tasks(X:np.ndarray,y:np.ndarray):\n",
    "    y_pos_mask = y == 1\n",
    "    X_postive,y_positive  = X[y_pos_mask],y[y_pos_mask]\n",
    "    X_negative,y_negative = X[~y_pos_mask],y[~y_pos_mask]\n",
    "    return X_postive,y_positive,X_negative,y_negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_splits=12\n",
    "skf = StratifiedKFold(n_splits=num_splits, shuffle=False)\n",
    "def load_range_dataset_w_benign(data_name, start_month, end_month, year, folder='data/',verbose = False):\n",
    "    \n",
    "    if start_month != end_month:\n",
    "        dataset_name = f'{year}-{start_month}to{year}-{end_month}'\n",
    "    else:\n",
    "        dataset_name = f'{year}-{start_month}'\n",
    "    \n",
    "    saved_data_file = os.path.join(folder, data_name, f'{dataset_name}_selected.npz')   \n",
    "\n",
    "    data = np.load(saved_data_file, allow_pickle=True)\n",
    "    if verbose:\n",
    "        print(f\"Loading data from {year}-{start_month} to {year}-{end_month}\")\n",
    "        print(folder)\n",
    "        print(saved_data_file)\n",
    "    X_train, y_train = data['X_train'], data['y_train']\n",
    "    y_mal_family = data['y_mal_family']\n",
    "\n",
    "    return X_train, y_train, y_mal_family\n",
    "def load_train_api_graph(train_start,test_end,verbose = False):\n",
    "    tasks = []\n",
    "    data = np.load(\"./gen_apigraph_drebin/2012-01to2012-12_selected.npz\")\n",
    "    X,y = data[\"X_train\"],data[\"y_train\"]\n",
    "    y_fam = y\n",
    "    X,y = get_binary_classification(X,y)\n",
    "    for _, test_index in skf.split(X, y):\n",
    "        X_split, y_split = X[test_index], y_fam[test_index]\n",
    "        tasks.append((X_split, y_split))\n",
    "    for year in range(train_start,test_end+1):\n",
    "        for month in range(1,13):\n",
    "            month = f'{month:02}'\n",
    "            X_train,y_train,y_train_family = load_range_dataset_w_benign(data_name=\"gen_apigraph_drebin/\",start_month=month,end_month=month,year=year,folder=\"\",verbose=True)\n",
    "            tasks.append([X_train,y_train])\n",
    "    # test_tasks =[]\n",
    "    # ## For the test dataset\n",
    "    # for year in range(test_start,test_end+1):\n",
    "    #     for month in range(1,13):\n",
    "    #         month = f'{month:02}'\n",
    "    #         X_test,y_test,_ = load_range_dataset_w_benign(data_name=\"gen_apigraph_drebin/\",start_month=month,end_month=month,year=year,folder=\"\") \n",
    "    #         # X_test,y_test = get_binary_classification(X_test,y_test)\n",
    "    #         test_tasks.append([torch.tensor(X_test,dtype=torch.float32),torch.tensor(y_test,dtype=torch.long)])\n",
    "    return tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from 2013-01 to 2013-01\n",
      "\n",
      "gen_apigraph_drebin/2013-01_selected.npz\n",
      "Loading data from 2013-02 to 2013-02\n",
      "\n",
      "gen_apigraph_drebin/2013-02_selected.npz\n",
      "Loading data from 2013-03 to 2013-03\n",
      "\n",
      "gen_apigraph_drebin/2013-03_selected.npz\n",
      "Loading data from 2013-04 to 2013-04\n",
      "\n",
      "gen_apigraph_drebin/2013-04_selected.npz\n",
      "Loading data from 2013-05 to 2013-05\n",
      "\n",
      "gen_apigraph_drebin/2013-05_selected.npz\n",
      "Loading data from 2013-06 to 2013-06\n",
      "\n",
      "gen_apigraph_drebin/2013-06_selected.npz\n",
      "Loading data from 2013-07 to 2013-07\n",
      "\n",
      "gen_apigraph_drebin/2013-07_selected.npz\n",
      "Loading data from 2013-08 to 2013-08\n",
      "\n",
      "gen_apigraph_drebin/2013-08_selected.npz\n",
      "Loading data from 2013-09 to 2013-09\n",
      "\n",
      "gen_apigraph_drebin/2013-09_selected.npz\n",
      "Loading data from 2013-10 to 2013-10\n",
      "\n",
      "gen_apigraph_drebin/2013-10_selected.npz\n",
      "Loading data from 2013-11 to 2013-11\n",
      "\n",
      "gen_apigraph_drebin/2013-11_selected.npz\n",
      "Loading data from 2013-12 to 2013-12\n",
      "\n",
      "gen_apigraph_drebin/2013-12_selected.npz\n",
      "Loading data from 2014-01 to 2014-01\n",
      "\n",
      "gen_apigraph_drebin/2014-01_selected.npz\n",
      "Loading data from 2014-02 to 2014-02\n",
      "\n",
      "gen_apigraph_drebin/2014-02_selected.npz\n",
      "Loading data from 2014-03 to 2014-03\n",
      "\n",
      "gen_apigraph_drebin/2014-03_selected.npz\n",
      "Loading data from 2014-04 to 2014-04\n",
      "\n",
      "gen_apigraph_drebin/2014-04_selected.npz\n",
      "Loading data from 2014-05 to 2014-05\n",
      "\n",
      "gen_apigraph_drebin/2014-05_selected.npz\n",
      "Loading data from 2014-06 to 2014-06\n",
      "\n",
      "gen_apigraph_drebin/2014-06_selected.npz\n",
      "Loading data from 2014-07 to 2014-07\n",
      "\n",
      "gen_apigraph_drebin/2014-07_selected.npz\n",
      "Loading data from 2014-08 to 2014-08\n",
      "\n",
      "gen_apigraph_drebin/2014-08_selected.npz\n",
      "Loading data from 2014-09 to 2014-09\n",
      "\n",
      "gen_apigraph_drebin/2014-09_selected.npz\n",
      "Loading data from 2014-10 to 2014-10\n",
      "\n",
      "gen_apigraph_drebin/2014-10_selected.npz\n",
      "Loading data from 2014-11 to 2014-11\n",
      "\n",
      "gen_apigraph_drebin/2014-11_selected.npz\n",
      "Loading data from 2014-12 to 2014-12\n",
      "\n",
      "gen_apigraph_drebin/2014-12_selected.npz\n",
      "Loading data from 2015-01 to 2015-01\n",
      "\n",
      "gen_apigraph_drebin/2015-01_selected.npz\n",
      "Loading data from 2015-02 to 2015-02\n",
      "\n",
      "gen_apigraph_drebin/2015-02_selected.npz\n",
      "Loading data from 2015-03 to 2015-03\n",
      "\n",
      "gen_apigraph_drebin/2015-03_selected.npz\n",
      "Loading data from 2015-04 to 2015-04\n",
      "\n",
      "gen_apigraph_drebin/2015-04_selected.npz\n",
      "Loading data from 2015-05 to 2015-05\n",
      "\n",
      "gen_apigraph_drebin/2015-05_selected.npz\n",
      "Loading data from 2015-06 to 2015-06\n",
      "\n",
      "gen_apigraph_drebin/2015-06_selected.npz\n",
      "Loading data from 2015-07 to 2015-07\n",
      "\n",
      "gen_apigraph_drebin/2015-07_selected.npz\n",
      "Loading data from 2015-08 to 2015-08\n",
      "\n",
      "gen_apigraph_drebin/2015-08_selected.npz\n",
      "Loading data from 2015-09 to 2015-09\n",
      "\n",
      "gen_apigraph_drebin/2015-09_selected.npz\n",
      "Loading data from 2015-10 to 2015-10\n",
      "\n",
      "gen_apigraph_drebin/2015-10_selected.npz\n",
      "Loading data from 2015-11 to 2015-11\n",
      "\n",
      "gen_apigraph_drebin/2015-11_selected.npz\n",
      "Loading data from 2015-12 to 2015-12\n",
      "\n",
      "gen_apigraph_drebin/2015-12_selected.npz\n",
      "Loading data from 2016-01 to 2016-01\n",
      "\n",
      "gen_apigraph_drebin/2016-01_selected.npz\n",
      "Loading data from 2016-02 to 2016-02\n",
      "\n",
      "gen_apigraph_drebin/2016-02_selected.npz\n",
      "Loading data from 2016-03 to 2016-03\n",
      "\n",
      "gen_apigraph_drebin/2016-03_selected.npz\n",
      "Loading data from 2016-04 to 2016-04\n",
      "\n",
      "gen_apigraph_drebin/2016-04_selected.npz\n",
      "Loading data from 2016-05 to 2016-05\n",
      "\n",
      "gen_apigraph_drebin/2016-05_selected.npz\n",
      "Loading data from 2016-06 to 2016-06\n",
      "\n",
      "gen_apigraph_drebin/2016-06_selected.npz\n",
      "Loading data from 2016-07 to 2016-07\n",
      "\n",
      "gen_apigraph_drebin/2016-07_selected.npz\n",
      "Loading data from 2016-08 to 2016-08\n",
      "\n",
      "gen_apigraph_drebin/2016-08_selected.npz\n",
      "Loading data from 2016-09 to 2016-09\n",
      "\n",
      "gen_apigraph_drebin/2016-09_selected.npz\n",
      "Loading data from 2016-10 to 2016-10\n",
      "\n",
      "gen_apigraph_drebin/2016-10_selected.npz\n",
      "Loading data from 2016-11 to 2016-11\n",
      "\n",
      "gen_apigraph_drebin/2016-11_selected.npz\n",
      "Loading data from 2016-12 to 2016-12\n",
      "\n",
      "gen_apigraph_drebin/2016-12_selected.npz\n",
      "Loading data from 2017-01 to 2017-01\n",
      "\n",
      "gen_apigraph_drebin/2017-01_selected.npz\n",
      "Loading data from 2017-02 to 2017-02\n",
      "\n",
      "gen_apigraph_drebin/2017-02_selected.npz\n",
      "Loading data from 2017-03 to 2017-03\n",
      "\n",
      "gen_apigraph_drebin/2017-03_selected.npz\n",
      "Loading data from 2017-04 to 2017-04\n",
      "\n",
      "gen_apigraph_drebin/2017-04_selected.npz\n",
      "Loading data from 2017-05 to 2017-05\n",
      "\n",
      "gen_apigraph_drebin/2017-05_selected.npz\n",
      "Loading data from 2017-06 to 2017-06\n",
      "\n",
      "gen_apigraph_drebin/2017-06_selected.npz\n",
      "Loading data from 2017-07 to 2017-07\n",
      "\n",
      "gen_apigraph_drebin/2017-07_selected.npz\n",
      "Loading data from 2017-08 to 2017-08\n",
      "\n",
      "gen_apigraph_drebin/2017-08_selected.npz\n",
      "Loading data from 2017-09 to 2017-09\n",
      "\n",
      "gen_apigraph_drebin/2017-09_selected.npz\n",
      "Loading data from 2017-10 to 2017-10\n",
      "\n",
      "gen_apigraph_drebin/2017-10_selected.npz\n",
      "Loading data from 2017-11 to 2017-11\n",
      "\n",
      "gen_apigraph_drebin/2017-11_selected.npz\n",
      "Loading data from 2017-12 to 2017-12\n",
      "\n",
      "gen_apigraph_drebin/2017-12_selected.npz\n",
      "Loading data from 2018-01 to 2018-01\n",
      "\n",
      "gen_apigraph_drebin/2018-01_selected.npz\n",
      "Loading data from 2018-02 to 2018-02\n",
      "\n",
      "gen_apigraph_drebin/2018-02_selected.npz\n",
      "Loading data from 2018-03 to 2018-03\n",
      "\n",
      "gen_apigraph_drebin/2018-03_selected.npz\n",
      "Loading data from 2018-04 to 2018-04\n",
      "\n",
      "gen_apigraph_drebin/2018-04_selected.npz\n",
      "Loading data from 2018-05 to 2018-05\n",
      "\n",
      "gen_apigraph_drebin/2018-05_selected.npz\n",
      "Loading data from 2018-06 to 2018-06\n",
      "\n",
      "gen_apigraph_drebin/2018-06_selected.npz\n",
      "Loading data from 2018-07 to 2018-07\n",
      "\n",
      "gen_apigraph_drebin/2018-07_selected.npz\n",
      "Loading data from 2018-08 to 2018-08\n",
      "\n",
      "gen_apigraph_drebin/2018-08_selected.npz\n",
      "Loading data from 2018-09 to 2018-09\n",
      "\n",
      "gen_apigraph_drebin/2018-09_selected.npz\n",
      "Loading data from 2018-10 to 2018-10\n",
      "\n",
      "gen_apigraph_drebin/2018-10_selected.npz\n",
      "Loading data from 2018-11 to 2018-11\n",
      "\n",
      "gen_apigraph_drebin/2018-11_selected.npz\n",
      "Loading data from 2018-12 to 2018-12\n",
      "\n",
      "gen_apigraph_drebin/2018-12_selected.npz\n"
     ]
    }
   ],
   "source": [
    "tasks_api = load_train_api_graph(2013,2018,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(tasks_api)):\n",
    "    X, y = tasks_api[j]\n",
    "    # Get indices of non-zero labels\n",
    "    pos_indices = np.where(y != 0)[0]  # Access the indices directly\n",
    "    # Get binary classification\n",
    "    X_np, y_np = get_binary_classification(X, y)\n",
    "    # Separate tasks into positive and negative\n",
    "    X_pos, y_pos, X_neg, y_neg = sepearte_tasks(X_np, y_np) \n",
    "    # Append metadata to positive and negative samples\n",
    "    X_pos = [np.append(data, 90 + j) for data in X_pos]\n",
    "    X_neg = [np.append(data, j) for data in X_neg]\n",
    "    np.save(f\"data_processed/test/api_graph/{90+j}.npy\", X_pos)\n",
    "    np.save(f\"data_processed/test/api_graph/{90+j}_labels.npy\", y[pos_indices])\n",
    "    np.save(f\"data_processed/test/api_graph/{j}.npy\", X_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_androzoo_derbin():\n",
    "    first_year_data_file = os.path.join(\"gen_androzoo_drebin\",\"2019-01to2019-12_selected.npz\")\n",
    "    first_year_data = np.load(first_year_data_file,allow_pickle=True)\n",
    "    X,y = first_year_data[\"X_train\"],first_year_data[\"y_train\"]\n",
    "    y_fam = y \n",
    "    X,y = get_binary_classification(X,y)\n",
    "    tasks = []\n",
    "    for _, test_index in skf.split(X, y):\n",
    "        X_split, y_split = X[test_index], y_fam[test_index]\n",
    "        tasks.append((X_split, y_split))\n",
    "    for year in range(2020,2022):\n",
    "            for month in range(1,13):\n",
    "                month = f'{month:02}'\n",
    "                X_train,y_train,_ = load_range_dataset_w_benign(data_name=\"gen_androzoo_drebin/\",start_month=month,end_month=month,year=year,folder=\"\")\n",
    "                # X_train,y_train = get_binary_classification(X_train,y_train)\n",
    "                tasks.append((X_train,y_train))\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_zoo = load_androzoo_derbin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(tasks_zoo)):\n",
    "    X, y = tasks_zoo[j]\n",
    "    # Get indices of non-zero labels\n",
    "    pos_indices = np.where(y != 0)[0]  # Access the indices directly\n",
    "    # Get binary classification\n",
    "    X_np, y_np = get_binary_classification(X, y)\n",
    "    # Separate tasks into positive and negative\n",
    "    X_pos, y_pos, X_neg, y_neg = sepearte_tasks(X_np, y_np) \n",
    "    # Append metadata to positive and negative samples\n",
    "    X_pos = [np.append(data, 90 + j) for data in X_pos]\n",
    "    X_neg = [np.append(data, j) for data in X_neg]\n",
    "    np.save(f\"data_processed/androzoo/{90+j}.npy\", X_pos)\n",
    "    np.save(f\"data_processed/androzoo/{90+j}_labels.npy\", y[pos_indices])\n",
    "    np.save(f\"data_processed/androzoo/{j}.npy\", X_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "num_splits=12\n",
    "skf = StratifiedKFold(n_splits=num_splits, shuffle=False)\n",
    "def load_bodmas(folder, dataset):\n",
    "    # Load the .npz file\n",
    "    saved_data_file = os.path.join(folder, dataset)\n",
    "    data = np.load(saved_data_file, allow_pickle=True)\n",
    "    X, y = data['X'], data['y']\n",
    "    df = pd.read_csv(\"./BODMAS/bodmas_metadata.csv\")\n",
    "    df['family_encoded'], unique_values =pd.factorize(df['family'].fillna(\"benign\"))\n",
    "    y_family = np.array(df['family_encoded'])\n",
    "    # Convert to PyTorch tensors\n",
    "    negative_indices = np.where(y == 0)[0] # Selecting the Benign Data\n",
    "    positive_indices = np.where(y !=0)[0] # Select the Attack \n",
    "    random_positive_indices = random.sample(positive_indices.tolist(),int(10/90*len(negative_indices)))\n",
    "    # print(len(random_positive_indices))\n",
    "    y_pos_neg_mask = np.concatenate([negative_indices,positive_indices])\n",
    "    y_pos_neg_mask.sort()\n",
    "    X, y ,y_family= X[y_pos_neg_mask], y[y_pos_neg_mask] ,y_family [y_pos_neg_mask]\n",
    "    X = normalize(X)\n",
    "    tasks = []\n",
    "    num_folds = 12\n",
    "    fold_size = len(X) // num_folds\n",
    "    tasks = []\n",
    "\n",
    "    for _, test_index in skf.split(X, y):\n",
    "        X_split, y_split,y_family_split = X[test_index], y[test_index],y_family[test_index]\n",
    "        tasks.append((X_split, y_split, y_family_split))\n",
    "    return tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks_bod  = load_bodmas(\"./BODMAS/\",\"bodmas.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for j in range(len(tasks_bod)):\n",
    "    X,y ,y_family= tasks_bod[j]\n",
    "    print(f\"Shape of X: {X.shape}, y :{y.shape} and y_family: {y_family.shape}\")\n",
    "    X_np,y_np = get_binary_classification(X,y)\n",
    "    X_pos,y_pos,X_neg,y_neg = sepearte_tasks(X_np,y_np)\n",
    "    pos_indices = np.where(y != 0)[0]  # Access the indices directly\n",
    "    X_pos = [np.append(data,90+j) for data in X_pos]\n",
    "    X_neg = [np.append(data,j) for data in X_neg]\n",
    "    # print(np.unique(y_family[pos_indices],return_counts=True) )\n",
    "    print(f\"Shape of X: {len(X_pos)},  and y_family: {len(y_family[pos_indices])}\")\n",
    "    np.save(f\"data_processed/test/bodmas/{90+j}.npy\",X_pos)\n",
    "    np.save(f\"data_processed/test/bodmas/{90+j}_labels.npy\", y[pos_indices])\n",
    "    np.save(f\"data_processed/test/bodmas/{j}.npy\",X_neg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
